{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b730f098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from strands.models import BedrockModel\n",
    "from strands import Agent\n",
    "from strands_tools import image_reader, file_read\n",
    "from video_reader import video_reader\n",
    "from strands.tools import tool\n",
    "\n",
    "\n",
    "# video_reader is already available as a built-in tool\n",
    "agent = Agent(tools=[image_reader, file_read, video_reader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba48f5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated multimodal system prompt to include video support\n",
    "MULTIMODAL_SYSTEM_PROMPT = \"\"\" You are a helpful assistant that can process documents, images, and videos. \n",
    "Analyze their contents and provide relevant information.\n",
    "\n",
    "You can:\n",
    "\n",
    "1. For PNG, JPEG/JPG, GIF, or WebP formats use image_reader to process file\n",
    "2. For PDF, csv, docx, xls or xlsx formats use file_read to process file  \n",
    "3. For MP4, MOV, AVI, MKV, WebM formats use video_reader to process file\n",
    "4. Just deliver the answer\n",
    "\n",
    "When displaying responses:\n",
    "- Format answers data in a human-readable way\n",
    "- Highlight important information\n",
    "- Handle errors appropriately\n",
    "- Convert technical terms to user-friendly language\n",
    "- Always reply in the original user language\n",
    "\n",
    "Always reply in the original user language.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# video_reader is available as built-in tool\n",
    "# video_reader is already imported above\n",
    "# load_tool(path=\"tools/video_reader.py\", name=\"video_reader\")  # This was causing errors\n",
    "\n",
    "session = boto3.Session(region_name='us-west-2')\n",
    "\n",
    "bedrock_model = BedrockModel(\n",
    "    #model_id=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "    model_id=\"us.amazon.nova-pro-v1:0\",\n",
    "    boto_session=session,\n",
    "    streaming=False\n",
    ")\n",
    "\n",
    "# Updated multimodal agent with video support\n",
    "multimodal_agent = Agent(\n",
    "    system_prompt=MULTIMODAL_SYSTEM_PROMPT,\n",
    "    tools=[image_reader, file_read, video_reader],\n",
    "    model=bedrock_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "example_usage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<thinking> Necesito analizar la imagen \"Ninas.jpeg\" para describir lo que veo en ella. Utilizaré la herramienta \"image_reader\" para procesar la imagen. </thinking>\n",
      "\n",
      "Tool #1: image_reader\n",
      "La imagen muestra a **dos niñas** jugando en un **parque**.\n",
      "\n",
      "- La niña de la izquierda lleva una chaqueta azul y pantalones azules.\n",
      "- La niña de la derecha lleva una chaqueta con diseño de alas y pantalones rosas. Ella parece estar lanzando algo, posiblemente una pelota.\n",
      "\n",
      "El entorno incluye:\n",
      "- **Césped verde** con algunas flores blancas.\n",
      "- **Árboles** en el fondo.\n",
      "- Una **valla** y una **cancha de tenis** al fondo.\n",
      "\n",
      "Las niñas parecen estar disfrutando de un día al aire libre en el parque.La imagen muestra a **dos niñas** jugando en un **parque**.\n",
      "\n",
      "- La niña de la izquierda lleva una chaqueta azul y pantalones azules.\n",
      "- La niña de la derecha lleva una chaqueta con diseño de alas y pantalones rosas. Ella parece estar lanzando algo, posiblemente una pelota.\n",
      "\n",
      "El entorno incluye:\n",
      "- **Césped verde** con algunas flores blancas.\n",
      "- **Árboles** en el fondo.\n",
      "- Una **valla** y una **cancha de tenis** al fondo.\n",
      "\n",
      "Las niñas parecen estar disfrutando de un día al aire libre en el parque.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ejemplos de uso del agente multimodal completo\n",
    "\n",
    "# 1. Analizar una imagen\n",
    "result_image = multimodal_agent(\"Analiza la imagen Ninas.jpeg y describe lo que ves\")\n",
    "print(result_image)\n",
    "\n",
    "# 2. Analizar un video\n",
    "# result_video = multimodal_agent(\"Analiza el video video.mp4 y explica qué está ocurriendo\")\n",
    "# print(result_video)\n",
    "\n",
    "# 3. Analizar un documento\n",
    "# result_doc = multimodal_agent(\"Resume el contenido del documento i-94-Enrique_mama.pdf\")\n",
    "# print(result_doc)\n",
    "\n",
    "# 4. Uso directo de las herramientas\n",
    "# video_analysis = multimodal_agent.tool.video_reader(\n",
    "#     video_path=\"video.mp4\", \n",
    "#     text_prompt=\"¿Cuáles son los elementos principales en este video?\"\n",
    "# )\n",
    "# print(video_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fee9acf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El análisis del video \"video.mp4\" muestra lo siguiente:\\n\\n- **Escena Principal:** Un niño está sentado en el suelo frente a un televisor.\\n- **Comportamiento del Niño:** El niño lleva auriculares y parece estar viendo una caricatura.\\n- **Entorno:** El televisor está colocado sobre un mueble de madera, y hay una ventana con persianas en el fondo.\\n- **Duración de la Actividad:** El niño permanece sentado durante todo el video, absorto en el contenido de la televisión.\\n\\n**Detalles Técnicos:**\\n- **Modelo Utilizado:** us.amazon.nova-pro-v1:0\\n- **Región:** us-west-2\\n- **Ruta del Video:** video.mp4\\n- **URI de S3:** s3://strands-video-analysis/videos/video.mp4\\n\\nEl video captura un momento en el que el niño está completamente inmerso en ver una caricatura en la televisión.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_video.message['content'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc6250f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<thinking> Necesito analizar el video \"video.mp4\" para determinar qué se ve en la televisión. Utilizaré la herramienta \"video_reader\" para procesar el video con un prompt específico para esta tarea. </thinking> \n",
      "Tool #3: video_reader\n",
      "El análisis del video \"video.mp4\" muestra lo siguiente:\n",
      "\n",
      "- **Escena Principal:** Un niño está sentado en el suelo frente a un televisor.\n",
      "- **Comportamiento del Niño:** El niño lleva auriculares y parece estar viendo una caricatura.\n",
      "- **Entorno:** El televisor está colocado sobre un mueble de madera, y hay una ventana con persianas en el fondo.\n",
      "- **Duración de la Actividad:** El niño permanece sentado durante todo el video, absorto en el contenido de la televisión.\n",
      "\n",
      "**Detalles Técnicos:**\n",
      "- **Modelo Utilizado:** us.amazon.nova-pro-v1:0\n",
      "- **Región:** us-west-2\n",
      "- **Ruta del Video:** video.mp4\n",
      "- **URI de S3:** s3://strands-video-analysis/videos/video.mp4\n",
      "\n",
      "El video captura un momento en el que el niño está completamente inmerso en ver una caricatura en la televisión.El análisis del video \"video.mp4\" muestra lo siguiente:\n",
      "\n",
      "- **Escena Principal:** Un niño está sentado en el suelo frente a un televisor.\n",
      "- **Comportamiento del Niño:** El niño lleva auriculares y parece estar viendo una caricatura.\n",
      "- **Entorno:** El televisor está colocado sobre un mueble de madera, y hay una ventana con persianas en el fondo.\n",
      "- **Duración de la Actividad:** El niño permanece sentado durante todo el video, absorto en el contenido de la televisión.\n",
      "\n",
      "**Detalles Técnicos:**\n",
      "- **Modelo Utilizado:** us.amazon.nova-pro-v1:0\n",
      "- **Región:** us-west-2\n",
      "- **Ruta del Video:** video.mp4\n",
      "- **URI de S3:** s3://strands-video-analysis/videos/video.mp4\n",
      "\n",
      "El video captura un momento en el que el niño está completamente inmerso en ver una caricatura en la televisión.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_video = multimodal_agent(\"Analiza el video video.mp4 y que se ve en la tele\")\n",
    "print(result_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec8d8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_image.message['content'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cc50623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'success', 'content': [{'text': '🎥 Video Analysis (Model: us.amazon.nova-pro-v1:0):\\n\\nAt the 7.3-second mark, the video shows a child sitting on the floor in front of a television.'}], 'video_path': 'video.mp4', 's3_uri': 's3://strands-video-analysis/videos/video.mp4', 'model_id_used': 'us.amazon.nova-pro-v1:0', 'region_used': 'us-west-2', 'model_response': {'role': 'assistant', 'content': [{'text': 'At the 7.3-second mark, the video shows a child sitting on the floor in front of a television.'}]}, 'toolUseId': 'tooluse_video_reader_934257536'}\n"
     ]
    }
   ],
   "source": [
    "video_analysis = multimodal_agent.tool.video_reader(\n",
    "     video_path=\"video.mp4\", \n",
    "     text_prompt=\"¿Cuáles son los elementos principales en este video?\"\n",
    " )\n",
    "print(video_analysis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
